key_mapping = {
    'self_attn.W_q': 'attn.W_q',
    'self_attn.W_k': 'attn.W_k',
    'self_attn.W_v': 'attn.W_v',
    'encoder_attention.fc_q': 'encoder_attention.W_q',
    'encoder_attention.fc_k': 'encoder_attention.W_k',
    'encoder_attention.fc_v': 'encoder_attention.W_v',
    'cross_attn.W_q': 'cross_attn.W_q',
    'cross_attn.W_k': 'cross_attn.W_k',
    'cross_attn.W_v': 'cross_attn.W_v',
    'self_attn.norm1.weight': 'norm1.weight',
    'self_attn.norm1.bias': 'norm1.bias',
    'self_attn.norm2.weight': 'norm2.weight',
    'self_attn.norm2.bias': 'norm2.bias',
    'norm3.weight': 'norm3.weight',
    'norm3.bias': 'norm3.bias',
    'positional_encoding.pe': 'pe',
    
    # Decoder layer 0
    'decoder_layers.0.self_attention.fc_q.bias': 'decoder_layers.0.self_attn.W_q.bias',
    'decoder_layers.0.self_attention.fc_q.weight': 'decoder_layers.0.self_attn.W_q.weight',
    'decoder_layers.0.self_attention.fc_k.weight': 'decoder_layers.0.self_attn.W_k.weight',
    'decoder_layers.0.self_attention.fc_k.bias': 'decoder_layers.0.self_attn.W_k.bias',
    'decoder_layers.0.self_attention.fc_v.weight': 'decoder_layers.0.self_attn.W_v.weight',
    'decoder_layers.0.self_attention.fc_v.bias': 'decoder_layers.0.self_attn.W_v.bias',
    'decoder_layers.0.self_attention.fc_o.weight': 'decoder_layers.0.self_attn.W_o.weight',
    'decoder_layers.0.self_attention.fc_o.bias': 'decoder_layers.0.self_attn.W_o.bias',
    
    # Decoder layer 1
    'decoder_layers.1.self_attention.fc_q.weight': 'decoder_layers.1.self_attn.W_q.weight',
    'decoder_layers.1.self_attention.fc_q.bias': 'decoder_layers.1.self_attn.W_q.bias',
    'decoder_layers.1.self_attention.fc_k.weight': 'decoder_layers.1.self_attn.W_k.weight',
    'decoder_layers.1.self_attention.fc_k.bias': 'decoder_layers.1.self_attn.W_k.bias',
    'decoder_layers.1.self_attention.fc_v.weight': 'decoder_layers.1.self_attn.W_v.weight',
    'decoder_layers.1.self_attention.fc_v.bias': 'decoder_layers.1.self_attn.W_v.bias',
    'decoder_layers.1.self_attention.fc_o.weight': 'decoder_layers.1.self_attn.W_o.weight',
    'decoder_layers.1.self_attention.fc_o.bias': 'decoder_layers.1.self_attn.W_o.bias',
    'decoder_layers.1.self_attention.fc_q.bias': 'decoder_layers.1.self_attention.fc_q.bias',
    'encoder_layers.1.self_attention.fc_k.weight': 'encoder_layers.1.self_attention.fc_k.weight',
    
    # Decoder layer 3
    'decoder_layers.3.self_attention.fc_q.weight': 'decoder_layers.3.self_attn.W_q.weight',
    'decoder_layers.3.self_attention.fc_q.bias': 'decoder_layers.3.self_attn.W_q.bias',
    'decoder_layers.3.self_attention.fc_k.weight': 'decoder_layers.3.self_attn.W_k.weight',
    'decoder_layers.3.self_attention.fc_k.bias': 'decoder_layers.3.self_attn.W_k.bias',
    'decoder_layers.3.self_attention.fc_v.weight': 'decoder_layers.3.self_attn.W_v.weight',
    'decoder_layers.3.self_attention.fc_v.bias': 'decoder_layers.3.self_attn.W_v.bias',
    'decoder_layers.3.self_attention.fc_o.weight': 'decoder_layers.3.self_attn.W_o.weight',
    'decoder_layers.3.self_attention.fc_o.bias': 'decoder_layers.3.self_attn.W_o.bias',
    
    # Decoder layer 4
    'decoder_layers.4.self_attention.fc_q.weight': 'decoder_layers.4.self_attn.W_q.weight',
    'decoder_layers.4.self_attention.fc_q.bias': 'decoder_layers.4.self_attn.W_q.bias',
    'decoder_layers.4.self_attention.fc_k.weight': 'decoder_layers.4.self_attn.W_k.weight',
    'decoder_layers.4.self_attention.fc_k.bias': 'decoder_layers.4.self_attn.W_k.bias',
    'decoder_layers.4.self_attention.fc_v.weight': 'decoder_layers.4.self_attn.W_v.weight',
    'decoder_layers.4.self_attention.fc_v.bias': 'decoder_layers.4.self_attn.W_v.bias',
    'decoder_layers.4.self_attention.fc_o.weight': 'decoder_layers.4.self_attn.W_o.weight',
    'decoder_layers.4.self_attention.fc_o.bias': 'decoder_layers.4.self_attn.W_o.bias',
    'decoder_layers.4.encoder_attention.fc_q.weight': 'decoder_layers.4.encoder_attn.W_q.weight',
    'decoder_layers.4.encoder_attention.fc_q.bias': 'decoder_layers.4.encoder_attn.W_q.bias',
    'decoder_layers.4.encoder_attention.fc_k.weight': 'decoder_layers.4.encoder_attn.W_k.weight',
    'decoder_layers.4.encoder_attention.fc_k.bias': 'decoder_layers.4.encoder_attn.W_k.bias',
    'decoder_layers.4.encoder_attention.fc_v.weight': 'decoder_layers.4.encoder_attn.W_v.weight',
    'decoder_layers.4.encoder_attention.fc_v.bias': 'decoder_layers.4.encoder_attn.W_v.bias',
    'decoder_layers.4.encoder_attention.fc_o.weight': 'decoder_layers.4.encoder_attn.W_o.weight',
    'decoder_layers.4.encoder_attention.fc_o.bias': 'decoder_layers.4.encoder_attn.W_o.bias',
    'decoder_layers.4.norm1.weight': 'decoder_layers.4.norm1.weight',
    'decoder_layers.4.norm1.bias': 'decoder_layers.4.norm1.bias',
    'decoder_layers.4.norm2.weight': 'decoder_layers.4.norm2.weight',
    'decoder_layers.4.norm2.bias': 'decoder_layers.4.norm2.bias',
    'decoder_layers.4.norm3.weight': 'decoder_layers.4.norm3.weight',
    'decoder_layers.4.norm3.bias': 'decoder_layers.4.norm3.bias',
    
    # Decoder layer 5
    'decoder_layers.5.self_attention.fc_q.weight': 'decoder_layers.5.self_attn.W_q.weight',
    'decoder_layers.5.self_attention.fc_q.bias': 'decoder_layers.5.self_attn.W_q.bias',
    'decoder_layers.5.self_attention.fc_k.weight': 'decoder_layers.5.self_attn.W_k.weight',
    'decoder_layers.5.self_attention.fc_k.bias': 'decoder_layers.5.self_attn.W_k.bias',
    'decoder_layers.5.self_attention.fc_v.weight': 'decoder_layers.5.self_attn.W_v.weight',
    'decoder_layers.5.self_attention.fc_v.bias': 'decoder_layers.5.self_attn.W_v.bias',
    'decoder_layers.5.self_attention.fc_o.weight': 'decoder_layers.5.self_attn.W_o.weight',
    'decoder_layers.5.self_attention.fc_o.bias': 'decoder_layers.5.self_attn.W_o.bias',
    'decoder_layers.5.norm1.weight': 'decoder_layers.5.norm1.weight',
    'decoder_layers.5.norm1.bias': 'decoder_layers.5.norm1.bias',
    'decoder_layers.5.norm2.weight': 'decoder_layers.5.norm2.weight',
    'decoder_layers.5.norm2.bias': 'decoder_layers.5.norm2.bias',
    'decoder_layers.5.norm3.weight': 'decoder_layers.5.norm3.weight',
    'decoder_layers.5.norm3.bias': 'decoder_layers.5.norm3.bias',
    # Decoder layer 6
    'decoder_layers.6.self_attention.fc_q.weight': 'decoder_layers.6.self_attn.W_q.weight',
    'decoder_layers.6.self_attention.fc_q.bias': 'decoder_layers.6.self_attn.W_q.bias',
    'decoder_layers.6.self_attention.fc_k.weight': 'decoder_layers.6.self_attn.W_k.weight',
    'decoder_layers.6.self_attention.fc_k.bias': 'decoder_layers.6.self_attn.W_k.bias',
    'decoder_layers.6.self_attention.fc_v.weight': 'decoder_layers.6.self_attn.W_v.weight',
    'decoder_layers.6.self_attention.fc_v.bias': 'decoder_layers.6.self_attn.W_v.bias',
    'decoder_layers.6.self_attention.fc_o.weight': 'decoder_layers.6.self_attn.W_o.weight',
    'decoder_layers.6.self_attention.fc_o.bias': 'decoder_layers.6.self_attn.W_o.bias',
    
    # Encoder layer 1
    'encoder_layers.1.self_attention.fc_q.weight': 'encoder_layers.1.self_attn.W_q.weight',
    'encoder_layers.1.self_attention.fc_q.bias': 'encoder_layers.1.self_attn.W_q.bias',
    'encoder_layers.1.self_attention.fc_k.weight': 'encoder_layers.1.self_attn.W_k.weight',
    'encoder_layers.1.self_attention.fc_k.bias': 'encoder_layers.1.self_attn.W_k.bias',
    'encoder_layers.1.self_attention.fc_v.weight': 'encoder_layers.1.self_attn.W_v.weight',
    'encoder_layers.1.self_attention.fc_v.bias': 'encoder_layers.1.self_attn.W_v.bias',
    'encoder_layers.1.self_attention.fc_o.weight': 'encoder_layers.1.self_attn.W_o.weight',
    'encoder_layers.1.self_attention.fc_o.bias': 'encoder_layers.1.self_attn.W_o.bias',
    'encoder_layers.1.self_attn.norm1.weight': 'encoder_layers.1.norm1.weight',
    'encoder_layers.1.self_attn.norm1.bias': 'encoder_layers.1.norm1.bias',
    'encoder_layers.1.self_attn.norm2.weight': 'encoder_layers.1.norm2.weight',
    'encoder_layers.1.self_attn.norm2.bias': 'encoder_layers.1.norm2.bias',
    'encoder_layers.1.norm3.weight': 'encoder_layers.1.norm3.weight',
    'encoder_layers.1.norm3.bias': 'encoder_layers.1.norm3.bias',
    # Encoder layer 2
    'encoder_layers.2.self_attention.fc_q.weight': 'encoder_layers.2.self_attn.W_q.weight',
    'encoder_layers.2.self_attention.fc_q.bias': 'encoder_layers.2.self_attn.W_q.bias',
    'encoder_layers.2.self_attention.fc_k.weight': 'encoder_layers.2.self_attn.W_k.weight',
    'encoder_layers.2.self_attention.fc_k.bias': 'encoder_layers.2.self_attn.W_k.bias',
    'encoder_layers.2.self_attention.fc_v.weight': 'encoder_layers.2.self_attn.W_v.weight',
    'encoder_layers.2.self_attention.fc_v.bias': 'encoder_layers.2.self_attn.W_v.bias',
    'encoder_layers.2.self_attention.fc_o.weight': 'encoder_layers.2.self_attn.W_o.weight',
    'encoder_layers.2.self_attention.fc_o.bias': 'encoder_layers.2.self_attn.W_o.bias',
    'encoder_layers.2.self_attn.norm1.weight': 'encoder_layers.2.norm1.weight',
    'encoder_layers.2.self_attn.norm1.bias': 'encoder_layers.2.norm1.bias',
    'encoder_layers.2.self_attn.norm2.weight': 'encoder_layers.2.norm2.weight',
    'encoder_layers.2.self_attn.norm2.bias': 'encoder_layers.2.norm2.bias',
    'encoder_layers.2.norm3.weight': 'encoder_layers.2.norm3.weight',
    'encoder_layers.2.norm3.bias': 'encoder_layers.2.norm3.bias',
    # Encoder layer 3
    'encoder_layers.3.self_attention.fc_q.weight': 'encoder_layers.3.self_attn.W_q.weight',
    'encoder_layers.3.self_attention.fc_q.bias': 'encoder_layers.3.self_attn.W_q.bias',
    'encoder_layers.3.self_attention.fc_k.weight': 'encoder_layers.3.self_attn.W_k.weight',
    'encoder_layers.3.self_attention.fc_k.bias': 'encoder_layers.3.self_attn.W_k.bias',
    'encoder_layers.3.self_attention.fc_v.weight': 'encoder_layers.3.self_attn.W_v.weight',
    'encoder_layers.3.self_attention.fc_v.bias': 'encoder_layers.3.self_attn.W_v.bias',
    'encoder_layers.3.self_attention.fc_o.weight': 'encoder_layers.3.self_attn.W_o.weight',
    'encoder_layers.3.self_attention.fc_o.bias': 'encoder_layers.3.self_attn.W_o.bias',
    'encoder_layers.3.self_attn.norm1.weight': 'encoder_layers.3.norm1.weight',
    'encoder_layers.3.self_attn.norm1.bias': 'encoder_layers.3.norm1.bias',
    'encoder_layers.3.self_attn.norm2.weight': 'encoder_layers.3.norm2.weight',
    'encoder_layers.3.self_attn.norm2.bias': 'encoder_layers.3.norm2.bias',
    'encoder_layers.3.norm3.weight': 'encoder_layers.3.norm3.weight',
    'encoder_layers.3.norm3.bias': 'encoder_layers.3.norm3.bias',
    # Encoder layer 4
    'encoder_layers.4.self_attention.fc_q.weight': 'encoder_layers.4.self_attn.W_q.weight',
    'encoder_layers.4.self_attention.fc_q.bias': 'encoder_layers.4.self_attn.W_q.bias',
    'encoder_layers.4.self_attention.fc_k.weight': 'encoder_layers.4.self_attn.W_k.weight',
    'encoder_layers.4.self_attention.fc_k.bias': 'encoder_layers.4.self_attn.W_k.bias',
    'encoder_layers.4.self_attention.fc_v.weight': 'encoder_layers.4.self_attn.W_v.weight',
    'encoder_layers.4.self_attention.fc_v.bias': 'encoder_layers.4.self_attn.W_v.bias',
    'encoder_layers.4.self_attention.fc_o.weight': 'encoder_layers.4.self_attn.W_o.weight',
    'encoder_layers.4.self_attention.fc_o.bias': 'encoder_layers.4.self_attn.W_o.bias',
    'encoder_layers.4.self_attn.norm1.weight': 'encoder_layers.4.norm1.weight',
    'encoder_layers.4.self_attn.norm1.bias': 'encoder_layers.4.norm1.bias',
    'encoder_layers.4.self_attn.norm2.weight': 'encoder_layers.4.norm2.weight',
    'encoder_layers.4.self_attn.norm2.bias': 'encoder_layers.4.norm2.bias',
    'encoder_layers.4.norm3.weight': 'encoder_layers.4.norm3.weight',
    'encoder_layers.4.norm3.bias': 'encoder_layers.4.norm3.bias',
    # Encoder layer 5
    'encoder_layers.5.self_attention.fc_q.weight': 'encoder_layers.5.self_attn.W_q.weight',
    'encoder_layers.5.self_attention.fc_q.bias': 'encoder_layers.5.self_attn.W_q.bias',
    'encoder_layers.5.self_attention.fc_k.weight': 'encoder_layers.5.self_attn.W_k.weight',
    'encoder_layers.5.self_attention.fc_k.bias': 'encoder_layers.5.self_attn.W_k.bias',
    'encoder_layers.5.self_attention.fc_v.weight': 'encoder_layers.5.self_attn.W_v.weight',
    'encoder_layers.5.self_attention.fc_v.bias': 'encoder_layers.5.self_attn.W_v.bias',
    'encoder_layers.5.self_attention.fc_o.weight': 'encoder_layers.5.self_attn.W_o.weight',
    'encoder_layers.5.self_attention.fc_o.bias': 'encoder_layers.5.self_attn.W_o.bias',
    'encoder_layers.5.self_attn.norm1.weight': 'encoder_layers.5.norm1.weight',
    'encoder_layers.5.self_attn.norm1.bias': 'encoder_layers.5.norm1.bias',
    'encoder_layers.5.self_attn.norm2.weight': 'encoder_layers.5.norm2.weight',
    'encoder_layers.5.self_attn.norm2.bias': 'encoder_layers.5.norm2.bias',
    'encoder_layers.5.norm3.weight': 'encoder_layers.5.norm3.weight',
    'encoder_layers.5.norm3.bias': 'encoder_layers.5.norm3.bias',
    
    
    
    
    'decoder_layers.0.encoder_attention.fc_o.bias': 'decoder_layers.0.self_attention.fc_o.bias',
    'decoder_layers.2.encoder_attention.fc_q.weight': 'decoder_layers.2.self_attention.fc_q.weight',
    'encoder_layers.1.self_attention.fc_q.bias': 'encoder_layers.1.self_attention.fc_q.bias',
    'decoder_layers.3.encoder_attention.fc_v.weight': 'decoder_layers.3.self_attention.fc_v.weight',
    'decoder_layers.4.encoder_attention.fc_k.bias': 'decoder_layers.4.self_attention.fc_k.bias',
    'encoder_layers.5.self_attention.fc_k.bias': 'encoder_layers.5.self_attention.fc_k.bias',
    'decoder_layers.0.encoder_attention.fc_v.bias': 'decoder_layers.0.self_attention.fc_v.bias',
    'decoder_layers.0.self_attention.fc_o.bias': 'decoder_layers.0.self_attention.fc_o.bias',
    'encoder_layers.5.self_attention.fc_q.weight': 'encoder_layers.5.self_attention.fc_q.weight',
    'decoder_layers.0.self_attention.fc_k.weight': 'decoder_layers.0.self_attention.fc_k.weight',
    'encoder_layers.4.self_attention.fc_q.weight': 'encoder_layers.4.self_attention.fc_q.weight',
    'decoder_layers.2.encoder_attention.fc_o.weight': 'decoder_layers.2.self_attention.fc_o.weight',
    'encoder_layers.4.self_attention.fc_o.bias': 'encoder_layers.4.self_attention.fc_o.bias',
    'encoder_layers.1.self_attention.fc_q.weight': 'encoder_layers.1.self_attention.fc_q.weight',
    'decoder_layers.5.encoder_attention.fc_k.bias': 'decoder_layers.5.self_attention.fc_k.bias',
    'decoder_layers.2.self_attention.fc_k.bias': 'decoder_layers.2.self_attention.fc_k.bias',
    'encoder_layers.4.self_attention.fc_q.bias': 'encoder_layers.4.self_attention.fc_q.bias',
    
    'decoder_layers.2.encoder_attention.fc_v.weight': 'decoder_layers.2.self_attention.fc_v.weight',
    'decoder_layers.1.encoder_attention.fc_q.weight': 'decoder_layers.1.self_attention.fc_q.weight',
    'decoder_layers.1.encoder_attention.fc_o.bias': 'decoder_layers.1.self_attention.fc_o.bias',
    'decoder_layers.4.encoder_attention.fc_q.bias': 'decoder_layers.4.self_attention.fc_q.bias',
    'decoder_layers.3.self_attention.fc_k.bias': 'decoder_layers.3.self_attention.fc_k.bias',
    'decoder_layers.2.self_attention.fc_q.weight': 'decoder_layers.2.self_attention.fc_q.weight',
    'decoder_layers.5.self_attention.fc_v.weight': 'decoder_layers.5.self_attention.fc_v.weight',
    'encoder_layers.2.self_attention.fc_q.weight': 'encoder_layers.2.self_attention.fc_q.weight',
    'encoder_layers.4.self_attention.fc_k.bias': 'encoder_layers.4.self_attention.fc_k.bias',
    'decoder_layers.4.self_attention.fc_k.weight': 'decoder_layers.4.self_attention.fc_k.weight',
    'decoder_layers.4.self_attention.fc_v.bias': 'decoder_layers.4.self_attention.fc_v.bias',
    'decoder_layers.3.self_attention.fc_v.bias': 'decoder_layers.3.self_attention.fc_v.bias',
    'encoder_layers.3.self_attention.fc_o.weight': 'encoder_layers.3.self_attention.fc_o.weight',
    'decoder_layers.1.encoder_attention.fc_k.weight': 'decoder_layers.1.self_attention.fc_k.weight',
    'encoder_layers.1.self_attention.fc_v.bias': 'encoder_layers.1.self_attention.fc_v.bias',
    'encoder_layers.4.self_attention.fc_k.weight': 'encoder_layers.4.self_attention.fc_k.weight',
    'decoder_layers.2.encoder_attention.fc_v.bias': 'decoder_layers.2.self_attention.fc_v.bias',
    'encoder_layers.1.self_attention.fc_o.weight': 'encoder_layers.1.self_attention.fc_o.weight',
    'decoder_layers.5.self_attention.fc_q.weight': 'decoder_layers.5.self_attention.fc_q.weight',
    'encoder_layers.0.self_attention.fc_q.bias': 'encoder_layers.0.self_attention.fc_q.bias',
    'decoder_layers.3.self_attention.fc_o.bias': 'decoder_layers.3.self_attention.fc_o.bias',
    'decoder_layers.0.self_attention.fc_q.weight': 'decoder_layers.0.self_attention.fc_q.weight',
    'decoder_layers.3.encoder_attention.fc_k.bias': 'decoder_layers.3.self_attention.fc_k.bias',
    'encoder_layers.5.self_attention.fc_o.bias': 'encoder_layers.5.self_attention.fc_o.bias',
    'decoder_layers.3.encoder_attention.fc_o.bias': 'decoder_layers.3.self_attention.fc_o.bias',
    'decoder_layers.3.self_attention.fc_k.weight': 'decoder_layers.3.self_attention.fc_k.weight',
    'decoder_layers.0.self_attention.fc_o.weight': 'decoder_layers.0.self_attention.fc_o.weight',
    'encoder_layers.2.self_attention.fc_k.bias': 'encoder_layers.2.self_attention.fc_k.bias',
    'encoder_layers.0.self_attention.fc_o.bias': 'encoder_layers.0.self_attention.fc_o.bias',
    'encoder_layers.4.self_attention.fc_v.weight': 'encoder_layers.4.self_attention.fc_v.weight',
    'encoder_layers.0.self_attention.fc_k.bias': 'encoder_layers.0.self_attention.fc_k.bias',
    'decoder_layers.3.encoder_attention.fc_q.bias': 'decoder_layers.3.self_attention.fc_q.bias',
    'decoder_layers.0.encoder_attention.fc_o.weight': 'decoder_layers.0.self_attention.fc_o.weight',
    'decoder_layers.0.self_attention.fc_q.bias': 'decoder_layers.0.self_attention.fc_q.bias',
    'decoder_layers.5.self_attention.fc_o.bias': 'decoder_layers.5.self_attention.fc_o.bias',
    'decoder_layers.1.encoder_attention.fc_o.weight': 'decoder_layers.1.self_attention.fc_o.weight',
    'encoder_layers.2.self_attention.fc_k.weight': 'encoder_layers.2.self_attention.fc_k.weight',
    'decoder_layers.0.self_attention.fc_v.weight': 'decoder_layers.0.self_attention.fc_v.weight',
    'decoder_layers.4.encoder_attention.fc_q.weight': 'decoder_layers.4.self_attention.fc_q.weight',
    'decoder_layers.3.self_attention.fc_v.weight': 'decoder_layers.3.self_attention.fc_v.weight',
    'encoder_layers.5.self_attention.fc_v.bias': 'encoder_layers.5.self_attention.fc_v.bias',
    'encoder_layers.3.self_attention.fc_q.weight': 'encoder_layers.3.self_attention.fc_q.weight',
    'encoder_layers.3.self_attention.fc_q.bias': 'encoder_layers.3.self_attention.fc_q.bias',
    'encoder_layers.0.self_attention.fc_v.bias': 'encoder_layers.0.self_attention.fc_v.bias',
    'decoder_layers.3.self_attention.fc_o.weight': 'decoder_layers.3.self_attention.fc_o.weight',
    'decoder_layers.3.encoder_attention.fc_q.weight': 'decoder_layers.3.self_attention.fc_q.weight',
    'decoder_layers.5.encoder_attention.fc_v.bias': 'decoder_layers.5.self',
    'encoder_layers.0.self_attention.fc_q.weight': 'encoder_layers.0.self_attn.W_q.weight',
    'encoder_layers.0.self_attention.fc_q.bias': 'encoder_layers.0.self_attn.W_q.bias',
    'encoder_layers.0.self_attention.fc_k.weight': 'encoder_layers.0.self_attn.W_k.weight',
    'encoder_layers.0.self_attention.fc_k.bias': 'encoder_layers.0.self_attn.W_k.bias',
    'encoder_layers.0.self_attention.fc_v.weight': 'encoder_layers.0.self_attn.W_v.weight',
    'encoder_layers.0.self_attention.fc_v.bias': 'encoder_layers.0.self_attn.W_v.bias',
    'encoder_layers.0.self_attention.fc_o.weight': 'encoder_layers.0.self_attn.W_o.weight',
    'encoder_layers.0.self_attention.fc_o.bias': 'encoder_layers.0.self_attn.W_o.bias',
    'encoder_layers.0.norm1.weight': 'encoder_layers.0.norm1.weight',
    'encoder_layers.0.norm1.bias': 'encoder_layers.0.norm1.bias',
    'encoder_layers.0.norm2.weight': 'encoder_layers.0.norm2.weight',
    'encoder_layers.0.norm2.bias': 'encoder_layers.0.norm2.bias',
    'decoder_layers.0.self_attention.fc_q.weight': 'decoder_layers.0.self_attn.W_q.weight',
    'decoder_layers.0.self_attention.fc_q.bias': 'decoder_layers.0.self_attn.W_q.bias',
    'decoder_layers.0.self_attention.fc_k.weight': 'decoder_layers.0.self_attn.W_k.weight',
    'decoder_layers.0.self_attention.fc_k.bias': 'decoder_layers.0.self_attn.W_k.bias',
    'decoder_layers.0.self_attention.fc_v.weight': 'decoder_layers.0.self_attn.W_v.weight',
    'decoder_layers.0.self_attention.fc_v.bias': 'decoder_layers.0.self_attn.W_v.bias',
    'decoder_layers.0.self_attention.fc_o.weight': 'decoder_layers.0.self_attn.W_o.weight',
    'decoder_layers.0.self_attention.fc_o.bias': 'decoder_layers.0.self_attn.W_o.bias',
    'decoder_layers.0.encoder_attention.fc_q.weight': 'decoder_layers.0.encoder_attn.W_q.weight',
    'decoder_layers.0.encoder_attention.fc_q.bias': 'decoder_layers.0.encoder_attn.W_q.bias',
    'decoder_layers.0.encoder_attention.fc_k.weight': 'decoder_layers.0.encoder_attn.W_k.weight',
    'decoder_layers.0.encoder_attention.fc_k.bias': 'decoder_layers.0.encoder_attn.W_k.bias',
    'decoder_layers.0.encoder_attention.fc_v.weight': 'decoder_layers.0.encoder_attn.W_v.weight',
    'decoder_layers.0.encoder_attention.fc_v.bias': 'decoder_layers.0.encoder_attn.W_v.bias',
    'decoder_layers.0.encoder_attention.fc_o.weight': 'decoder_layers.0.encoder_attn.W_o.weight',
    'decoder_layers.0.encoder_attention.fc_o.bias': 'decoder_layers.0.encoder_attn.W_o.bias',
    'decoder_layers.0.norm1.weight': 'decoder_layers.0.norm1.weight',
    'decoder_layers.0.norm1.bias': 'decoder_layers.0.norm1.bias',
    'decoder_layers.0.norm2.weight': 'decoder_layers.0.norm2.weight',
    'decoder_layers.0.norm2.bias': 'decoder_layers.0.norm2.bias',
    'decoder_layers.0.norm3.weight': 'decoder_layers.0.norm3.weight',
    'decoder_layers.0.norm3.bias': 'decoder_layers.0.norm3.bias',
}